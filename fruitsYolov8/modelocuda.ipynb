{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Output de nvcc --version:\n"," nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:41:10_Pacific_Daylight_Time_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n","\n","CUDA version: 11.8\n"]}],"source":["import subprocess\n","\n","def get_cuda_version():\n","    try:\n","        result = subprocess.run(['nvcc', '--version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n","        output = result.stdout.decode('utf-8')\n","        error_output = result.stderr.decode('utf-8')\n","        \n","        if result.returncode != 0:\n","            print(\"Error ejecutando nvcc:\", error_output)\n","            return None\n","        \n","        print(\"Output de nvcc --version:\\n\", output)\n","        \n","        lines = output.split('\\n')\n","        for line in lines:\n","            if 'release' in line:\n","                cuda_version = line.strip().split('release ')[-1].split(',')[0]\n","                return cuda_version\n","    except Exception as e:\n","        print(\"Error:\", e)\n","        return None\n","\n","cuda_version = get_cuda_version()\n","if cuda_version:\n","    print(\"CUDA version:\", cuda_version)\n","else:\n","    print(\"CUDA no está instalado o no se puede detectar la versión.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["^C\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip uninstall torch torchvision torchaudio"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pip install typing-extensions==4.5.0"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA disponible: True\n","Versión de PyTorch: 2.0.1+cu118\n"]}],"source":["import torch\n","\n","print(\"CUDA disponible:\", torch.cuda.is_available())  # Esto debería devolver True si CUDA está configurado correctamente\n","print(\"Versión de PyTorch:\", torch.__version__)  # Debería mostrar la versión de PyTorch instalada\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82069,"status":"ok","timestamp":1713919829818,"user":{"displayName":"Giancarlos Mamani Benitez","userId":"02836706634622118321"},"user_tz":300},"id":"QTBa4vsCeOll","outputId":"53c65e2d-488c-452a-d9e0-08d625986464"},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA available: True\n","PyTorch version: 2.0.1+cu118\n","CUDA version: 11.8\n","CuDNN version: 8700\n"]}],"source":["import torch\n","\n","# Verificar si CUDA está disponible\n","cuda_available = torch.cuda.is_available()\n","\n","# Imprimir la disponibilidad de CUDA\n","print(\"CUDA available:\", cuda_available)\n","\n","# Imprimir la versión de PyTorch\n","print(\"PyTorch version:\", torch.__version__)\n","\n","# Si CUDA está disponible, imprimir la versión de CUDA y CuDNN\n","if cuda_available:\n","    print(\"CUDA version:\", torch.version.cuda)\n","    print(\"CuDNN version:\", torch.backends.cudnn.version())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%pip install 'tensorflow<=2.13.1' ultralytics\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.16  Python-3.9.13 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1050, 3072MiB)\n","Setup complete  (8 CPUs, 15.8 GB RAM, 245.6/730.1 GB disk)\n"]}],"source":["import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["TensorFlow version: 2.13.1\n","WARNING:tensorflow:From C:\\Users\\Giancarlos\\AppData\\Local\\Temp\\ipykernel_4764\\2117654923.py:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.config.list_physical_devices('GPU')` instead.\n","GPU available: False\n"]}],"source":["import tensorflow as tf\n","print(\"TensorFlow version:\", tf.__version__)\n","print(\"GPU available:\", tf.test.is_gpu_available())"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":5400,"status":"ok","timestamp":1713919835211,"user":{"displayName":"Giancarlos Mamani Benitez","userId":"02836706634622118321"},"user_tz":300},"id":"r04xuxzZegq0"},"outputs":[],"source":["from ultralytics import YOLO\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["model = YOLO(r'C:\\Users\\Giancarlos\\Documents\\modeloyolo\\yolov8n.pt')"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["New https://pypi.org/project/ultralytics/8.2.19 available  Update with 'pip install -U ultralytics'\n","Ultralytics YOLOv8.2.16  Python-3.9.13 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1050, 3072MiB)\n","\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=C:\\Users\\Giancarlos\\Documents\\modeloyolo\\yolov8n.pt, data=C:\\Users\\Giancarlos\\Documents\\Seminario1_Proyecto\\Seminario1\\fruitsYolov8\\configvsc.yaml, epochs=20, time=None, patience=20, batch=8, imgsz=320, save=True, save_period=-1, cache=True, device=0, workers=2, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0001, warmup_epochs=2, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.1, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train5\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n","Model summary: 225 layers, 3011628 parameters, 3011612 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train5', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Giancarlos\\Documents\\Dataset\\Dataset\\labels\\train\\durazno.cache... 1344 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1344/1344 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.4GB RAM): 100%|██████████| 1344/1344 [00:04<00:00, 304.76it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Giancarlos\\Documents\\Dataset\\Dataset\\labels\\val\\durazno.cache... 448 images, 0 backgrounds, 0 corrupt: 100%|██████████| 448/448 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB RAM): 100%|██████████| 448/448 [00:03<00:00, 113.66it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Plotting labels to runs\\detect\\train5\\labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0001), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n","Image sizes 320 train, 320 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns\\detect\\train5\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       1/20     0.493G     0.9281      1.545      1.092         25        320: 100%|██████████| 168/168 [00:30<00:00,  5.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:06<00:00,  4.50it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.292      0.824      0.492      0.367\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       2/20     0.411G     0.8585       1.01      1.061         19        320: 100%|██████████| 168/168 [00:27<00:00,  6.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.07it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.375      0.723      0.532      0.401\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       3/20     0.422G     0.7867     0.9241      1.043         29        320: 100%|██████████| 168/168 [00:25<00:00,  6.64it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.24it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.504      0.822      0.554      0.424\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       4/20     0.426G     0.7501     0.8501      1.038         25        320: 100%|██████████| 168/168 [00:25<00:00,  6.66it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.17it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.394      0.782      0.541      0.408\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       5/20     0.426G     0.7159     0.7718      1.022         22        320: 100%|██████████| 168/168 [00:24<00:00,  6.79it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.46it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.445      0.832      0.648       0.51\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       6/20     0.428G     0.6902      0.755      1.014         18        320: 100%|██████████| 168/168 [00:26<00:00,  6.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.07it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.593      0.856      0.698      0.548\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       7/20     0.426G     0.6671     0.7061      1.004         20        320: 100%|██████████| 168/168 [00:24<00:00,  6.80it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.14it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.662      0.762      0.699      0.562\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       8/20     0.426G     0.6177     0.6457     0.9859         29        320: 100%|██████████| 168/168 [00:24<00:00,  6.77it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.36it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.656      0.864      0.777      0.631\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       9/20     0.426G     0.6194     0.6222     0.9811         19        320: 100%|██████████| 168/168 [00:24<00:00,  6.75it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.45it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.785      0.816      0.863        0.7\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      10/20     0.426G      0.587      0.584     0.9691         20        320: 100%|██████████| 168/168 [00:26<00:00,  6.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.16it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.786      0.874      0.872       0.72\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Closing dataloader mosaic\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      11/20     0.426G     0.6058      0.896     0.9478         15        320: 100%|██████████| 168/168 [00:25<00:00,  6.64it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.753      0.844      0.805      0.664\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      12/20     0.426G     0.5869     0.7313     0.9252          8        320: 100%|██████████| 168/168 [00:26<00:00,  6.45it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.33it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.905      0.874      0.954      0.811\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      13/20     0.428G     0.5529     0.6065     0.9112         11        320: 100%|██████████| 168/168 [00:25<00:00,  6.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.47it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.892      0.901      0.946      0.804\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      14/20     0.426G     0.5554     0.5602     0.9137          8        320: 100%|██████████| 168/168 [00:25<00:00,  6.65it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.61it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.948      0.841      0.945      0.813\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      15/20     0.426G     0.5231     0.5193     0.9026          8        320: 100%|██████████| 168/168 [00:26<00:00,  6.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  5.88it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.932      0.905      0.959       0.83\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      16/20     0.426G      0.513     0.4777     0.8934          9        320: 100%|██████████| 168/168 [00:26<00:00,  6.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.33it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.952      0.926      0.963      0.838\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      17/20     0.426G     0.4971     0.4441     0.9033          8        320: 100%|██████████| 168/168 [00:25<00:00,  6.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.39it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.946      0.879      0.965      0.839\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      18/20     0.426G     0.4891     0.4212     0.8902          9        320: 100%|██████████| 168/168 [00:25<00:00,  6.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.30it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503       0.95      0.897      0.965      0.846\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      19/20     0.426G     0.4723     0.3893     0.8845         11        320: 100%|██████████| 168/168 [00:26<00:00,  6.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.934      0.894      0.962      0.849\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      20/20     0.426G     0.4635     0.3721     0.8841          8        320: 100%|██████████| 168/168 [00:25<00:00,  6.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  6.41it/s]"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.952      0.888      0.967      0.856\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","20 epochs completed in 0.181 hours.\n","Optimizer stripped from runs\\detect\\train5\\weights\\last.pt, 6.2MB\n","Optimizer stripped from runs\\detect\\train5\\weights\\best.pt, 6.2MB\n","\n","Validating runs\\detect\\train5\\weights\\best.pt...\n","Ultralytics YOLOv8.2.16  Python-3.9.13 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1050, 3072MiB)\n","Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"name":"stderr","output_type":"stream","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 28/28 [00:04<00:00,  5.60it/s]\n"]},{"name":"stdout","output_type":"stream","text":["                   all        448        503      0.952      0.888      0.967      0.855\n","               durazno        448        132      0.937      0.784      0.951      0.848\n","             mandarina        448        127      0.958      0.953      0.987      0.911\n","               manzana        448        131      0.931       0.87      0.962      0.856\n","               platano        448        113      0.982      0.947      0.967      0.805\n","Speed: 0.2ms preprocess, 3.6ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1mruns\\detect\\train5\u001b[0m\n"]}],"source":["results = model.train(data=r'C:\\Users\\Giancarlos\\Documents\\Seminario1_Proyecto\\Seminario1\\fruitsYolov8\\configvsc.yaml', \n","                      device=0 ,epochs=20, imgsz=320, batch=8, workers=2, optimizer='AdamW',\n","                      lr0=0.001, weight_decay=0.0001, warmup_epochs=2, warmup_bias_lr=0.1, \n","                      label_smoothing=0.1, amp=True, cache=True, patience=20)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["model = YOLO(r'C:\\Users\\Giancarlos\\Downloads\\entre3masdata50.zip\\detect\\train\\weights\\best.pt')"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGiancarlos\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mplatano\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m505.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m      3\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mboxes  \u001b[38;5;66;03m# Boxes object for bounding box outputs\u001b[39;00m\n","\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["results = model(\"https://www.shutterstock.com/image-photo/peach-leaf-full-depth-field-260nw-667915150.jpg\") \n","for result in results:\n","    boxes = result.boxes  # Boxes object for bounding box outputs\n","    masks = result.masks  # Masks object for segmentation masks outputs\n","    keypoints = result.keypoints  # Keypoints object for pose outputs\n","    probs = result.probs  # Probs object for classification outputs\n","    obb = result.obb  # Oriented boxes object for OBB outputs\n","    result.show()  # display to screen\n","    result.save(filename=\"result.jpg\")  # save to disk"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: Invalid requirement: \"'tensorflow-cpu==2.13.1'\"\n"]}],"source":["%pip install 'tensorflow-cpu==2.13.1'"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2.13.1\n"]}],"source":["import tensorflow as tf\n","print(tf.__version__)  # Esto debería mostrar una versión de TensorFlow igual o inferior a 2.13.1"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics YOLOv8.2.16  Python-3.9.13 torch-2.0.1+cu118 CUDA:0 (NVIDIA GeForce GTX 1050, 3072MiB)\n","Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs\\detect\\train5\\weights\\best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 8, 2100) (5.9 MB)\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxruntime-gpu'] not found, attempting AutoUpdate...\n","Defaulting to user installation because normal site-packages is not writeable\n","Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n","Collecting onnxruntime-gpu\n","  Downloading onnxruntime_gpu-1.18.0-cp39-cp39-win_amd64.whl.metadata (4.4 kB)\n","Requirement already satisfied: coloredlogs in c:\\users\\giancarlos\\appdata\\roaming\\python\\python39\\site-packages (from onnxruntime-gpu) (15.0.1)\n","Requirement already satisfied: flatbuffers in c:\\users\\giancarlos\\appdata\\roaming\\python\\python39\\site-packages (from onnxruntime-gpu) (24.3.25)\n","Requirement already satisfied: numpy>=1.21.6 in c:\\users\\giancarlos\\appdata\\roaming\\python\\python39\\site-packages (from onnxruntime-gpu) (1.24.3)\n","Requirement already satisfied: packaging in c:\\users\\giancarlos\\appdata\\roaming\\python\\python39\\site-packages (from onnxruntime-gpu) (24.0)\n","Requirement already satisfied: protobuf in c:\\users\\giancarlos\\appdata\\roaming\\python\\python39\\site-packages (from onnxruntime-gpu) (3.20.3)\n","Requirement already satisfied: sympy in c:\\users\\giancarlos\\appdata\\roaming\\python\\python39\\site-packages (from onnxruntime-gpu) (1.12)\n","Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\giancarlos\\appdata\\roaming\\python\\python39\\site-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\giancarlos\\appdata\\roaming\\python\\python39\\site-packages (from sympy->onnxruntime-gpu) (1.3.0)\n","Requirement already satisfied: pyreadline3 in c:\\users\\giancarlos\\appdata\\roaming\\python\\python39\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime-gpu) (3.4.1)\n","Downloading onnxruntime_gpu-1.18.0-cp39-cp39-win_amd64.whl (157.7 MB)\n","   ---------------------------------------- 157.7/157.7 MB 5.8 MB/s eta 0:00:00\n","Installing collected packages: onnxruntime-gpu\n","Successfully installed onnxruntime-gpu-1.18.0\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  55.5s, installed 1 package: ['onnxruntime-gpu']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.13.1...\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n","============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n","verbose: False, log level: Level.ERROR\n","======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m simplifying with onnxsim 0.4.36...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success  9.0s, saved as 'runs\\detect\\train5\\weights\\best.onnx' (11.6 MB)\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.17.5...\n","\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success  132.4s, saved as 'runs\\detect\\train5\\weights\\best_saved_model' (29.1 MB)\n","\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.13.1...\n","\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success  0.0s, saved as 'runs\\detect\\train5\\weights\\best_saved_model\\best_float32.tflite' (11.6 MB)\n","\n","Export complete (134.0s)\n","Results saved to \u001b[1mC:\\Users\\Giancarlos\\Documents\\Seminario1_Proyecto\\Seminario1\\fruitsYolov8\\runs\\detect\\train5\\weights\u001b[0m\n","Predict:         yolo predict task=detect model=runs\\detect\\train5\\weights\\best_saved_model\\best_float32.tflite imgsz=320  \n","Validate:        yolo val task=detect model=runs\\detect\\train5\\weights\\best_saved_model\\best_float32.tflite imgsz=320 data=C:\\Users\\Giancarlos\\Documents\\Seminario1_Proyecto\\Seminario1\\fruitsYolov8\\configvsc.yaml  \n","Visualize:       https://netron.app\n"]},{"data":{"text/plain":["'runs\\\\detect\\\\train5\\\\weights\\\\best_saved_model\\\\best_float32.tflite'"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["model.export(format=\"tflite\")"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["modeltf = YOLO(r'C:\\Users\\Giancarlos\\Documents\\Seminario1_Proyecto\\Seminario1\\fruitsYolov8\\runs\\detect\\train5\\weights\\best_saved_model\\best_float32.tflite')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"]},{"ename":"ValueError","evalue":"Cannot set tensor: Dimension mismatch. Got 640 but expected 320 for dimension 1 of input 0.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodeltf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mGiancarlos\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDocuments\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDataset\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDataset\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mplatano\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m505.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m      3\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mboxes  \u001b[38;5;66;03m# Boxes object for bounding box outputs\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ultralytics\\engine\\model.py:177\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    156\u001b[0m     source: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    157\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    159\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m    160\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m    An alias for the predict method, enabling the model instance to be callable.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m        (List[ultralytics.engine.results.Results]): A list of prediction results, encapsulated in the Results class.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source, stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ultralytics\\engine\\model.py:453\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ultralytics\\engine\\predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ultralytics\\engine\\predictor.py:248\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 248\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    250\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ultralytics\\engine\\predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    138\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    141\u001b[0m )\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\ultralytics\\nn\\autobackend.py:576\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    574\u001b[0m     scale, zero_point \u001b[38;5;241m=\u001b[39m details[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    575\u001b[0m     im \u001b[38;5;241m=\u001b[39m (im \u001b[38;5;241m/\u001b[39m scale \u001b[38;5;241m+\u001b[39m zero_point)\u001b[38;5;241m.\u001b[39mastype(details[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# de-scale\u001b[39;00m\n\u001b[1;32m--> 576\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetails\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpreter\u001b[38;5;241m.\u001b[39minvoke()\n\u001b[0;32m    578\u001b[0m y \u001b[38;5;241m=\u001b[39m []\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\lite\\python\\interpreter.py:720\u001b[0m, in \u001b[0;36mInterpreter.set_tensor\u001b[1;34m(self, tensor_index, value)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index, value):\n\u001b[0;32m    705\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \n\u001b[0;32m    707\u001b[0m \u001b[38;5;124;03m  Note this copies data in `value`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001b[39;00m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 720\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSetTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mValueError\u001b[0m: Cannot set tensor: Dimension mismatch. Got 640 but expected 320 for dimension 1 of input 0."]}],"source":["results = modeltf(r'C:\\Users\\Giancarlos\\Documents\\Dataset\\Dataset\\data\\image\\platano\\505.jpg') \n","for result in results:\n","    boxes = result.boxes  # Boxes object for bounding box outputs\n","    masks = result.masks  # Masks object for segmentation masks outputs\n","    keypoints = result.keypoints  # Keypoints object for pose outputs\n","    probs = result.probs  # Probs object for classification outputs\n","    obb = result.obb  # Oriented boxes object for OBB outputs\n","    result.show()  # display to screen\n","    result.save(filename=\"result1.jpg\")  # save to disk"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = model.train(data='/media/pi/Maxell8/Modelo/Seminario1/fruitsYolov8/configvsc.yaml', epochs=100, imgsz=640, task='detect')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = YOLO('path/to/best.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["validation_results = model.val(data='/media/pi/Maxell8/Modelo/Seminario1/fruitsYolov8/configvsc.yaml',\n","                               imgsz=640,\n","                               batch=16,\n","                               conf=0.25,\n","                               iou=0.6,\n","                               device='0',\n","                               split= 'test')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
