{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R_lK5RDodrbW","executionInfo":{"status":"ok","timestamp":1713919747753,"user_tz":300,"elapsed":22329,"user":{"displayName":"Giancarlos Mamani Benitez","userId":"02836706634622118321"}},"outputId":"cb176516-d2ab-4467-ad40-8eb87d1a3304"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QTBa4vsCeOll","executionInfo":{"status":"ok","timestamp":1713919829818,"user_tz":300,"elapsed":82069,"user":{"displayName":"Giancarlos Mamani Benitez","userId":"02836706634622118321"}},"outputId":"53c65e2d-488c-452a-d9e0-08d625986464"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.2.2-py3-none-any.whl (750 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.8/750.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Collecting thop>=0.1.1 (from ultralytics)\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.2\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","import pandas as pd\n","import numpy as np"],"metadata":{"id":"r04xuxzZegq0","executionInfo":{"status":"ok","timestamp":1713919835211,"user_tz":300,"elapsed":5400,"user":{"displayName":"Giancarlos Mamani Benitez","userId":"02836706634622118321"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!yolo detect train model=yolov8x.pt data='/content/drive/MyDrive/2024-1/Seminario1/ProyectoTesis/fruitsYolov8/config2.yaml' epochs=1 imgsz=640"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6-9y1piIelFE","executionInfo":{"status":"ok","timestamp":1713919988374,"user_tz":300,"elapsed":137537,"user":{"displayName":"Giancarlos Mamani Benitez","userId":"02836706634622118321"}},"outputId":"be0a6250-29c1-4d82-c610-3a3565f73e97"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt to 'yolov8x.pt'...\n","100% 131M/131M [00:00<00:00, 193MB/s]\n","Ultralytics YOLOv8.2.2 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=/content/drive/MyDrive/2024-1/Seminario1/ProyectoTesis/fruitsYolov8/config2.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 16.4MB/s]\n","2024-04-24 00:51:05.820625: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-24 00:51:05.820708: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-24 00:51:05.822516: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Overriding model.yaml nc=80 with nc=4\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n","  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n","  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n","  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n","  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n","  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n","  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n","  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n","  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n","  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n"," 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n"," 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 22        [15, 18, 21]  1   8721820  ultralytics.nn.modules.head.Detect           [4, [320, 640, 640]]          \n","Model summary: 365 layers, 68156460 parameters, 68156444 gradients, 258.1 GFLOPs\n","\n","Transferred 589/595 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/2024-1/Seminario1/ProyectoTesis/fruitsYolov8/data/labels/train/durazno.cache... 206 images, 0 backgrounds, 0 corrupt: 100% 206/206 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/2024-1/Seminario1/ProyectoTesis/fruitsYolov8/data/labels/val/durazno.cache... 206 images, 0 backgrounds, 0 corrupt: 100% 206/206 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","  0% 0/13 [00:00<?, ?it/s]^C\n"]}]},{"cell_type":"code","source":["!yolo export model=yolov8x.pt format=onnx  # export official model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GyT5AdDz0C8H","executionInfo":{"status":"ok","timestamp":1713920151331,"user_tz":300,"elapsed":46473,"user":{"displayName":"Giancarlos Mamani Benitez","userId":"02836706634622118321"}},"outputId":"2899184f-0a49-45e7-a5bd-499a33aa3643"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.2 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n","YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8x.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (130.5 MB)\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n","Collecting onnx>=1.12.0\n","  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.9/15.9 MB 83.0 MB/s eta 0:00:00\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (1.25.2)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (3.20.3)\n","Installing collected packages: onnx\n","Successfully installed onnx-1.16.0\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 13.1s, installed 1 package: ['onnx>=1.12.0']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 24.8s, saved as 'yolov8x.onnx' (260.4 MB)\n","\n","Export complete (39.5s)\n","Results saved to \u001b[1m/content\u001b[0m\n","Predict:         yolo predict task=detect model=yolov8x.onnx imgsz=640  \n","Validate:        yolo val task=detect model=yolov8x.onnx imgsz=640 data=coco.yaml  \n","Visualize:       https://netron.app\n","💡 Learn more at https://docs.ultralytics.com/modes/export\n"]}]},{"cell_type":"code","source":["!yolo detect val model='/content/yolov8x.onnx' data='/content/drive/MyDrive/2024-1/Seminario1/ProyectoTesis/fruitsYolov8/config2.yaml'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3tzjOSOK0hF","executionInfo":{"status":"ok","timestamp":1713921227639,"user_tz":300,"elapsed":1060869,"user":{"displayName":"Giancarlos Mamani Benitez","userId":"02836706634622118321"}},"outputId":"47d02764-7d9b-4148-945e-5cbf0d89969f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.2 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n","Loading /content/yolov8x.onnx for ONNX Runtime inference...\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxruntime'] not found, attempting AutoUpdate...\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.8/6.8 MB 24.9 MB/s eta 0:00:00\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 106.2 MB/s eta 0:00:00\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 237.0 MB/s eta 0:00:00\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.3\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 9.5s, installed 1 package: ['onnxruntime']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","Forcing batch=1 square inference (1,3,640,640) for non-PyTorch models\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/2024-1/Seminario1/ProyectoTesis/fruitsYolov8/data/labels/val/durazno.cache... 206 images, 0 backgrounds, 0 corrupt: 100% 206/206 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 206/206 [17:15<00:00,  5.03s/it]\n","                   all        206        206      0.139     0.0245     0.0787     0.0563\n","                person        206         54          0          0          0          0\n","               bicycle        206         50          0          0          0          0\n","                   car        206         51      0.556      0.098      0.315      0.225\n","            motorcycle        206         51          0          0          0          0\n","Speed: 1.9ms preprocess, 4726.3ms inference, 0.0ms loss, 15.3ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/val\n"]}]},{"cell_type":"code","source":["!yolo detect predict model='/content/yolov8x.onnx' source='https://5aldia.cl/wp-content/uploads/2018/03/durazno.jpg'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3pqSoqliKLKk","executionInfo":{"status":"ok","timestamp":1713921281669,"user_tz":300,"elapsed":15912,"user":{"displayName":"Giancarlos Mamani Benitez","userId":"02836706634622118321"}},"outputId":"b9b1b59d-e4fd-4027-8396-8f9ec7e4226e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.2 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n","Loading /content/yolov8x.onnx for ONNX Runtime inference...\n","\n","Downloading https://5aldia.cl/wp-content/uploads/2018/03/durazno.jpg to 'durazno.jpg'...\n","100% 115k/115k [00:00<00:00, 852kB/s] \n","image 1/1 /content/durazno.jpg: 640x640 2 apples, 1 orange, 5910.9ms\n","Speed: 4.7ms preprocess, 5910.9ms inference, 1847.9ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}]},{"cell_type":"code","source":["!yolo detect predict model='/content/yolov8x.onnx' source='https://www.recetasnestle.com.pe/sites/default/files/2022-07/tipos-de-manzana-royal-gala.jpg'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vwXMPx29rwZr","executionInfo":{"status":"ok","timestamp":1713921749068,"user_tz":300,"elapsed":14639,"user":{"displayName":"Giancarlos Mamani Benitez","userId":"02836706634622118321"}},"outputId":"105a412a-b7af-4c7c-8608-a034c26ac644"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.2 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n","Loading /content/yolov8x.onnx for ONNX Runtime inference...\n","\n","Downloading https://www.recetasnestle.com.pe/sites/default/files/2022-07/tipos-de-manzana-royal-gala.jpg to 'tipos-de-manzana-royal-gala.jpg'...\n","100% 13.4k/13.4k [00:00<00:00, 33.2MB/s]\n","image 1/1 /content/tipos-de-manzana-royal-gala.jpg: 640x640 1 apple, 5777.4ms\n","Speed: 4.6ms preprocess, 5777.4ms inference, 1768.9ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}]},{"cell_type":"code","source":["model2 = YOLO('/content/yolov8n.onnx')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t6hnlHnI-rAq","executionInfo":{"status":"ok","timestamp":1713674853004,"user_tz":300,"elapsed":12,"user":{"displayName":"Giancarlos MB","userId":"11466231362687463704"}},"outputId":"7bcab0d3-433a-442e-a10e-0fb3531717ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"]}]},{"cell_type":"code","source":["model1.predict('/content/drive/MyDrive/ProyectoTesis/fruitsYolov8/frutaPrueba.jpg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"faY1Dm2FkKUy","executionInfo":{"status":"ok","timestamp":1713674866769,"user_tz":300,"elapsed":2576,"user":{"displayName":"Giancarlos MB","userId":"11466231362687463704"}},"outputId":"f4bd83f1-e738-44b5-bc8b-59ade8581859"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading /content/yolov8n.torchscript for TorchScript inference...\n","\n","image 1/1 /content/drive/MyDrive/ProyectoTesis/fruitsYolov8/frutaPrueba.jpg: 640x640 (no detections), 622.1ms\n","Speed: 17.5ms preprocess, 622.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"execute_result","data":{"text/plain":["[ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '10', 11: '11', 12: '12', 13: '13', 14: '14', 15: '15', 16: '16', 17: '17', 18: '18', 19: '19', 20: '20', 21: '21', 22: '22', 23: '23', 24: '24', 25: '25', 26: '26', 27: '27', 28: '28', 29: '29', 30: '30', 31: '31', 32: '32', 33: '33', 34: '34', 35: '35', 36: '36', 37: '37', 38: '38', 39: '39', 40: '40', 41: '41', 42: '42', 43: '43', 44: '44', 45: '45', 46: '46', 47: '47', 48: '48', 49: '49', 50: '50', 51: '51', 52: '52', 53: '53', 54: '54', 55: '55', 56: '56', 57: '57', 58: '58', 59: '59', 60: '60', 61: '61', 62: '62', 63: '63', 64: '64', 65: '65', 66: '66', 67: '67', 68: '68', 69: '69', 70: '70', 71: '71', 72: '72', 73: '73', 74: '74', 75: '75', 76: '76', 77: '77', 78: '78', 79: '79'}\n"," obb: None\n"," orig_img: array([[[255, 253, 253],\n","         [255, 253, 253],\n","         [255, 253, 253],\n","         ...,\n","         [255, 253, 253],\n","         [255, 253, 253],\n","         [255, 253, 253]],\n"," \n","        [[255, 253, 253],\n","         [255, 253, 253],\n","         [255, 253, 253],\n","         ...,\n","         [255, 253, 253],\n","         [255, 253, 253],\n","         [255, 253, 253]],\n"," \n","        [[255, 253, 253],\n","         [255, 253, 253],\n","         [255, 253, 253],\n","         ...,\n","         [255, 253, 253],\n","         [255, 253, 253],\n","         [255, 253, 253]],\n"," \n","        ...,\n"," \n","        [[  1,   1,   1],\n","         [  1,   1,   1],\n","         [  1,   1,   1],\n","         ...,\n","         [  1,   1,   1],\n","         [  1,   1,   1],\n","         [  1,   1,   1]],\n"," \n","        [[  1,   1,   1],\n","         [  1,   1,   1],\n","         [  1,   1,   1],\n","         ...,\n","         [  1,   1,   1],\n","         [  1,   1,   1],\n","         [  1,   1,   1]],\n"," \n","        [[  1,   1,   1],\n","         [  1,   1,   1],\n","         [  1,   1,   1],\n","         ...,\n","         [  1,   1,   1],\n","         [  1,   1,   1],\n","         [  1,   1,   1]]], dtype=uint8)\n"," orig_shape: (956, 1300)\n"," path: '/content/drive/MyDrive/ProyectoTesis/fruitsYolov8/frutaPrueba.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict3'\n"," speed: {'preprocess': 17.534494400024414, 'inference': 622.1108436584473, 'postprocess': 1.7566680908203125}]"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["model2.predict('/content/drive/MyDrive/ProyectoTesis/fruitsYolov8/frutaPrueba.jpg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tLIe_Yzbx8ye","executionInfo":{"status":"ok","timestamp":1713675133920,"user_tz":300,"elapsed":460,"user":{"displayName":"Giancarlos MB","userId":"11466231362687463704"}},"outputId":"f1e6ee72-ac43-4c2a-b6b1-5b4a05decbb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/drive/MyDrive/ProyectoTesis/fruitsYolov8/frutaPrueba.jpg: 640x640 (no detections), 238.0ms\n","Speed: 10.5ms preprocess, 238.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"execute_result","data":{"text/plain":["[ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '10', 11: '11', 12: '12', 13: '13', 14: '14', 15: '15', 16: '16', 17: '17', 18: '18', 19: '19', 20: '20', 21: '21', 22: '22', 23: '23', 24: '24', 25: '25', 26: '26', 27: '27', 28: '28', 29: '29', 30: '30', 31: '31', 32: '32', 33: '33', 34: '34', 35: '35', 36: '36', 37: '37', 38: '38', 39: '39', 40: '40', 41: '41', 42: '42', 43: '43', 44: '44', 45: '45', 46: '46', 47: '47', 48: '48', 49: '49', 50: '50', 51: '51', 52: '52', 53: '53', 54: '54', 55: '55', 56: '56', 57: '57', 58: '58', 59: '59', 60: '60', 61: '61', 62: '62', 63: '63', 64: '64', 65: '65', 66: '66', 67: '67', 68: '68', 69: '69', 70: '70', 71: '71', 72: '72', 73: '73', 74: '74', 75: '75', 76: '76', 77: '77', 78: '78', 79: '79'}\n"," obb: None\n"," orig_img: array([[[255, 253, 253],\n","         [255, 253, 253],\n","         [255, 253, 253],\n","         ...,\n","         [255, 253, 253],\n","         [255, 253, 253],\n","         [255, 253, 253]],\n"," \n","        [[255, 253, 253],\n","         [255, 253, 253],\n","         [255, 253, 253],\n","         ...,\n","         [255, 253, 253],\n","         [255, 253, 253],\n","         [255, 253, 253]],\n"," \n","        [[255, 253, 253],\n","         [255, 253, 253],\n","         [255, 253, 253],\n","         ...,\n","         [255, 253, 253],\n","         [255, 253, 253],\n","         [255, 253, 253]],\n"," \n","        ...,\n"," \n","        [[  1,   1,   1],\n","         [  1,   1,   1],\n","         [  1,   1,   1],\n","         ...,\n","         [  1,   1,   1],\n","         [  1,   1,   1],\n","         [  1,   1,   1]],\n"," \n","        [[  1,   1,   1],\n","         [  1,   1,   1],\n","         [  1,   1,   1],\n","         ...,\n","         [  1,   1,   1],\n","         [  1,   1,   1],\n","         [  1,   1,   1]],\n"," \n","        [[  1,   1,   1],\n","         [  1,   1,   1],\n","         [  1,   1,   1],\n","         ...,\n","         [  1,   1,   1],\n","         [  1,   1,   1],\n","         [  1,   1,   1]]], dtype=uint8)\n"," orig_shape: (956, 1300)\n"," path: '/content/drive/MyDrive/ProyectoTesis/fruitsYolov8/frutaPrueba.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict3'\n"," speed: {'preprocess': 10.4522705078125, 'inference': 238.0368709564209, 'postprocess': 1.356363296508789}]"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["!yolo segment train data='/content/drive/MyDrive/ProyectoTesis/fruitsYolov8/config2.yaml' model=yolov8n-seg.yaml epochs=5 imgsz=640"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83upax9qAt4x","executionInfo":{"status":"ok","timestamp":1713675838980,"user_tz":300,"elapsed":6830,"user":{"displayName":"Giancarlos MB","userId":"11466231362687463704"}},"outputId":"1c573656-465a-4731-daba-596435bbda68"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.2 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.yaml, data=/content/drive/MyDrive/ProyectoTesis/fruitsYolov8/config2.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train2\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 517, in get_dataset\n","    data = check_det_dataset(self.args.data)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/data/utils.py\", line 299, in check_det_dataset\n","    data[\"names\"] = check_class_names(data[\"names\"])\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/nn/autobackend.py\", line 35, in check_class_names\n","    raise KeyError(\n","KeyError: '4-class dataset requires class indices 0-3, but you have invalid class indices 1-4 defined in your dataset YAML.'\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/yolo\", line 8, in <module>\n","    sys.exit(entrypoint())\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 582, in entrypoint\n","    getattr(model, mode)(**overrides)  # default args from model\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 654, in train\n","    self.trainer = (trainer or self._smart_load(\"trainer\"))(overrides=args, _callbacks=self.callbacks)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/segment/train.py\", line 30, in __init__\n","    super().__init__(cfg, overrides, _callbacks)\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 130, in __init__\n","    self.trainset, self.testset = self.get_dataset()\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\", line 521, in get_dataset\n","    raise RuntimeError(emojis(f\"Dataset '{clean_url(self.args.data)}' error ❌ {e}\")) from e\n","RuntimeError: Dataset '/content/drive/MyDrive/ProyectoTesis/fruitsYolov8/config2.yaml' error ❌ '4-class dataset requires class indices 0-3, but you have invalid class indices 1-4 defined in your dataset YAML.'\n"]}]},{"cell_type":"code","source":["!yolo export model=yolov8n-seg.yaml format=onnx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9IsyS1nvtvl_","executionInfo":{"status":"ok","timestamp":1713675903533,"user_tz":300,"elapsed":9457,"user":{"displayName":"Giancarlos MB","userId":"11466231362687463704"}},"outputId":"26aae13a-643c-47ef-dcf0-1175ebf11d82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.2 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n","YOLOv8n-seg summary (fused): 195 layers, 3404320 parameters, 0 gradients, 12.6 GFLOPs\n","\n","\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n-seg.yaml' with input shape (1, 3, 640, 640) BCHW and output shape(s) ((1, 116, 8400), (1, 32, 160, 160)) (0.0 MB)\n","\n","\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n","\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 2.2s, saved as 'yolov8n-seg.onnx' (13.2 MB)\n","\n","Export complete (5.6s)\n","Results saved to \u001b[1m/content\u001b[0m\n","Predict:         yolo predict task=segment model=yolov8n-seg.onnx imgsz=640  \n","Validate:        yolo val task=segment model=yolov8n-seg.onnx imgsz=640 data=None  \n","Visualize:       https://netron.app\n","💡 Learn more at https://docs.ultralytics.com/modes/export\n"]}]},{"cell_type":"code","source":["model3 = YOLO('/content/yolov8n-seg.onnx')"],"metadata":{"id":"cZxW_lN2CyjK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!yolo segment predict model='/content/yolov8n-seg.onnx' source='https://statics-cuidateplus.marca.com/cms/platanos_0.jpg'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2RNmKn2IC_a5","executionInfo":{"status":"ok","timestamp":1713676051047,"user_tz":300,"elapsed":9337,"user":{"displayName":"Giancarlos MB","userId":"11466231362687463704"}},"outputId":"39b64e17-9378-4255-f34e-37b544983aea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.2 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n","Loading /content/yolov8n-seg.onnx for ONNX Runtime inference...\n","\n","Found https://statics-cuidateplus.marca.com/cms/platanos_0.jpg locally at platanos_0.jpg\n","image 1/1 /content/platanos_0.jpg: 640x640 (no detections), 482.8ms\n","Speed: 9.0ms preprocess, 482.8ms inference, 2719.9ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/segment/predict\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}]},{"cell_type":"code","source":["model23 = YOLO('/content/yolov8n.onnx')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vq3KZxKW0V2s","executionInfo":{"status":"ok","timestamp":1713672146990,"user_tz":300,"elapsed":999,"user":{"displayName":"Giancarlos MB","userId":"11466231362687463704"}},"outputId":"f6f003f0-1f67-4b55-cbd9-b75a15f0caca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n"]}]},{"cell_type":"code","source":["model3.predict('/content/drive/MyDrive/ProyectoTesis/fruitsYolov8/data/images/train/mandarina/0.jpg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A7DuGKqH0dfD","executionInfo":{"status":"ok","timestamp":1713676149208,"user_tz":300,"elapsed":2281,"user":{"displayName":"Giancarlos MB","userId":"11466231362687463704"}},"outputId":"b59fd5c4-0491-4cc4-cd77-8bdca1f9bd16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading /content/yolov8n-seg.onnx for ONNX Runtime inference...\n","\n","image 1/1 /content/drive/MyDrive/ProyectoTesis/fruitsYolov8/data/images/train/mandarina/0.jpg: 640x640 (no detections), 504.3ms\n","Speed: 15.7ms preprocess, 504.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n"]},{"output_type":"execute_result","data":{"text/plain":["[ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '10', 11: '11', 12: '12', 13: '13', 14: '14', 15: '15', 16: '16', 17: '17', 18: '18', 19: '19', 20: '20', 21: '21', 22: '22', 23: '23', 24: '24', 25: '25', 26: '26', 27: '27', 28: '28', 29: '29', 30: '30', 31: '31', 32: '32', 33: '33', 34: '34', 35: '35', 36: '36', 37: '37', 38: '38', 39: '39', 40: '40', 41: '41', 42: '42', 43: '43', 44: '44', 45: '45', 46: '46', 47: '47', 48: '48', 49: '49', 50: '50', 51: '51', 52: '52', 53: '53', 54: '54', 55: '55', 56: '56', 57: '57', 58: '58', 59: '59', 60: '60', 61: '61', 62: '62', 63: '63', 64: '64', 65: '65', 66: '66', 67: '67', 68: '68', 69: '69', 70: '70', 71: '71', 72: '72', 73: '73', 74: '74', 75: '75', 76: '76', 77: '77', 78: '78', 79: '79'}\n"," obb: None\n"," orig_img: array([[[232, 206, 200],\n","         [231, 205, 199],\n","         [230, 204, 198],\n","         ...,\n","         [175, 154, 146],\n","         [173, 154, 146],\n","         [172, 153, 145]],\n"," \n","        [[233, 207, 201],\n","         [232, 206, 200],\n","         [231, 205, 199],\n","         ...,\n","         [175, 154, 146],\n","         [173, 154, 146],\n","         [172, 153, 145]],\n"," \n","        [[232, 206, 200],\n","         [232, 206, 200],\n","         [231, 205, 199],\n","         ...,\n","         [175, 154, 146],\n","         [173, 154, 146],\n","         [173, 154, 146]],\n"," \n","        ...,\n"," \n","        [[  6,   2,   1],\n","         [  7,   3,   2],\n","         [  4,   2,   1],\n","         ...,\n","         [  0,   0,   1],\n","         [  0,   0,   1],\n","         [  0,   0,   1]],\n"," \n","        [[  2,   0,   0],\n","         [  3,   1,   1],\n","         [  5,   0,   1],\n","         ...,\n","         [  0,   0,   0],\n","         [  1,   1,   1],\n","         [  1,   1,   1]],\n"," \n","        [[  3,   0,   2],\n","         [  2,   0,   1],\n","         [  4,   0,   0],\n","         ...,\n","         [  0,   1,   0],\n","         [  3,   1,   0],\n","         [  3,   1,   0]]], dtype=uint8)\n"," orig_shape: (224, 224)\n"," path: '/content/drive/MyDrive/ProyectoTesis/fruitsYolov8/data/images/train/mandarina/0.jpg'\n"," probs: None\n"," save_dir: 'runs/segment/predict2'\n"," speed: {'preprocess': 15.651702880859375, 'inference': 504.28295135498047, 'postprocess': 1.7883777618408203}]"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["import torch"],"metadata":{"id":"zrR7E2SG2vF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!yolo detect val model='/content/yolov8n.torchscript' data='/content/drive/MyDrive/ProyectoTesis/fruitsYolov8/config2.yaml'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPs5FG3X1S_k","executionInfo":{"status":"ok","timestamp":1713672931286,"user_tz":300,"elapsed":143788,"user":{"displayName":"Giancarlos MB","userId":"11466231362687463704"}},"outputId":"b9c7cdc0-b9fe-4032-8e8b-4d343536ad87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.2 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n","Loading /content/yolov8n.torchscript for TorchScript inference...\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/ProyectoTesis/fruitsYolov8/data/labels/val/durazno... 206 images, 0 backgrounds, 0 corrupt: 100% 206/206 [01:00<00:00,  3.39it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/ProyectoTesis/fruitsYolov8/data/labels/val/durazno.cache\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 13/13 [01:10<00:00,  5.43s/it]\n","                   all        206        206          0          0          0          0\n","Speed: 9.9ms preprocess, 307.3ms inference, 0.0ms loss, 10.4ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val3\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/val\n"]}]},{"cell_type":"code","source":["!yolo predict model='/content/yolov8n.torchscript' source='https://statics-cuidateplus.marca.com/cms/platanos_0.jpg'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DwRPcpCB2aJa","executionInfo":{"status":"ok","timestamp":1713672706455,"user_tz":300,"elapsed":8748,"user":{"displayName":"Giancarlos MB","userId":"11466231362687463704"}},"outputId":"2c633d42-0f87-4050-c652-fb235733c1ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n","Ultralytics YOLOv8.2.2 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n","Loading /content/yolov8n.torchscript for TorchScript inference...\n","\n","Found https://statics-cuidateplus.marca.com/cms/platanos_0.jpg locally at platanos_0.jpg\n","image 1/1 /content/platanos_0.jpg: 640x640 (no detections), 452.4ms\n","Speed: 10.1ms preprocess, 452.4ms inference, 1859.8ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}]},{"cell_type":"code","source":["!yolo detect model='/content/yolov8n.torchscript' source='/content/drive/MyDrive/ProyectoTesis/fruitsYolov8/data/images/train/durazno/0.jpg'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"amFq0tbL3WHB","executionInfo":{"status":"ok","timestamp":1713673039085,"user_tz":300,"elapsed":3641,"user":{"displayName":"Giancarlos MB","userId":"11466231362687463704"}},"outputId":"19a72070-4d3d-46ce-826d-1823337dcf6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ 'mode' argument is missing. Valid modes are {'train', 'predict', 'val', 'track', 'benchmark', 'export'}. Using default 'mode=train'.\n","WARNING ⚠️ 'data' argument is missing. Using default 'data=coco8.yaml'.\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/yolo\", line 8, in <module>\n","    sys.exit(entrypoint())\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 582, in entrypoint\n","    getattr(model, mode)(**overrides)  # default args from model\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 635, in train\n","    self._check_is_pytorch_model()\n","  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 258, in _check_is_pytorch_model\n","    raise TypeError(\n","TypeError: model='/content/yolov8n.torchscript' should be a *.pt PyTorch model to run this method, but is a different format. PyTorch models can train, val, predict and export, i.e. 'model.train(data=...)', but exported formats like ONNX, TensorRT etc. only support 'predict' and 'val' modes, i.e. 'yolo predict model=yolov8n.onnx'.\n","To run CUDA or MPS inference please pass the device argument directly in your inference command, i.e. 'model.predict(source=..., device=0)'\n"]}]}]}